{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMVvgYrgosDq5X9UWaUxX0b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvrjsharma/HugginFace_Gradio/blob/main/DDColor_Gradio_Demo_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/piddnad/DDColor.git"
      ],
      "metadata": {
        "id": "svmR1KiCyrFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DDColor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxsER1SRzKRF",
        "outputId": "5cb5e427-83de-4a1f-de4e-d10126a97547"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DDColor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "1DXDJQk1yj5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio -q"
      ],
      "metadata": {
        "id": "VTA1TwvFk5KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm gradio_imageslider -q"
      ],
      "metadata": {
        "id": "3q2P7gxy628B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL98iRYByFjA"
      },
      "outputs": [],
      "source": [
        "!pip install modelscope -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from modelscope.hub.snapshot_download import snapshot_download\n",
        "\n",
        "model_dir = snapshot_download('damo/cv_ddcolor_image-colorization', cache_dir='./modelscope')\n",
        "print('model assets saved to %s'%model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGEePNw3ye84",
        "outputId": "e993f1e9-5975-4e66-f026-d9ec86e58b49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-01-19 03:47:46,140 - modelscope - INFO - PyTorch version 2.1.0+cu121 Found.\n",
            "2024-01-19 03:47:46,144 - modelscope - INFO - TensorFlow version 2.15.0 Found.\n",
            "2024-01-19 03:47:46,145 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
            "2024-01-19 03:47:46,147 - modelscope - INFO - No valid ast index found from /root/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
            "2024-01-19 03:47:46,210 - modelscope - INFO - Loading done! Current index file version is 1.11.0, with md5 d1bf70dc840bbc78c6b639e013c9762e and a total number of 953 components indexed\n",
            "2024-01-19 03:47:50,058 - modelscope - WARNING - Model revision not specified, use revision: v1.02\n",
            "Downloading: 100%|██████████| 1.39k/1.39k [00:00<00:00, 6.37MB/s]\n",
            "Downloading: 100%|██████████| 235k/235k [00:00<00:00, 7.11MB/s]\n",
            "Downloading: 100%|██████████| 199k/199k [00:00<00:00, 6.00MB/s]\n",
            "Downloading: 100%|██████████| 94.9k/94.9k [00:00<00:00, 5.95MB/s]\n",
            "Downloading: 100%|██████████| 117k/117k [00:00<00:00, 4.92MB/s]\n",
            "Downloading: 100%|█████████▉| 870M/870M [00:13<00:00, 67.0MB/s]\n",
            "Downloading: 100%|██████████| 3.44k/3.44k [00:00<00:00, 13.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model assets saved to ./modelscope/damo/cv_ddcolor_image-colorization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/DDColor')\n",
        "\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from basicsr.archs.ddcolor_arch import DDColor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import gradio as gr\n",
        "from gradio_imageslider import ImageSlider\n",
        "import uuid\n",
        "from PIL import Image\n",
        "\n",
        "model_path = 'modelscope/damo/cv_ddcolor_image-colorization/pytorch_model.pt'\n",
        "input_size = 512\n",
        "model_size = 'large'\n",
        "\n",
        "\n",
        "# Create Image Colorization Pipeline\n",
        "class ImageColorizationPipeline(object):\n",
        "\n",
        "    def __init__(self, model_path, input_size=256, model_size='large'):\n",
        "\n",
        "        self.input_size = input_size\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.device('cuda')\n",
        "        else:\n",
        "            self.device = torch.device('cpu')\n",
        "\n",
        "        if model_size == 'tiny':\n",
        "            self.encoder_name = 'convnext-t'\n",
        "        else:\n",
        "            self.encoder_name = 'convnext-l'\n",
        "\n",
        "        self.decoder_type = \"MultiScaleColorDecoder\"\n",
        "\n",
        "        if self.decoder_type == 'MultiScaleColorDecoder':\n",
        "            self.model = DDColor(\n",
        "                encoder_name=self.encoder_name,\n",
        "                decoder_name='MultiScaleColorDecoder',\n",
        "                input_size=[self.input_size, self.input_size],\n",
        "                num_output_channels=2,\n",
        "                last_norm='Spectral',\n",
        "                do_normalize=False,\n",
        "                num_queries=100,\n",
        "                num_scales=3,\n",
        "                dec_layers=9,\n",
        "            ).to(self.device)\n",
        "        else:\n",
        "            self.model = DDColor(\n",
        "                encoder_name=self.encoder_name,\n",
        "                decoder_name='SingleColorDecoder',\n",
        "                input_size=[self.input_size, self.input_size],\n",
        "                num_output_channels=2,\n",
        "                last_norm='Spectral',\n",
        "                do_normalize=False,\n",
        "                num_queries=256,\n",
        "            ).to(self.device)\n",
        "\n",
        "        self.model.load_state_dict(\n",
        "            torch.load(model_path, map_location=torch.device('cpu'))['params'],\n",
        "            strict=False)\n",
        "        self.model.eval()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def process(self, img):\n",
        "        self.height, self.width = img.shape[:2]\n",
        "        img = (img / 255.0).astype(np.float32)\n",
        "        orig_l = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:, :, :1]  # (h, w, 1)\n",
        "\n",
        "        # resize rgb image -> lab -> get grey -> rgb\n",
        "        img = cv2.resize(img, (self.input_size, self.input_size))\n",
        "        img_l = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:, :, :1]\n",
        "        img_gray_lab = np.concatenate((img_l, np.zeros_like(img_l), np.zeros_like(img_l)), axis=-1)\n",
        "        img_gray_rgb = cv2.cvtColor(img_gray_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "        tensor_gray_rgb = torch.from_numpy(img_gray_rgb.transpose((2, 0, 1))).float().unsqueeze(0).to(self.device)\n",
        "        output_ab = self.model(tensor_gray_rgb).cpu()  # (1, 2, self.height, self.width)\n",
        "\n",
        "        # resize ab -> concat original l -> rgb\n",
        "        output_ab_resize = F.interpolate(output_ab, size=(self.height, self.width))[0].float().numpy().transpose(1, 2, 0)\n",
        "        output_lab = np.concatenate((orig_l, output_ab_resize), axis=-1)\n",
        "        output_bgr = cv2.cvtColor(output_lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        output_img = (output_bgr * 255.0).round().astype(np.uint8)\n",
        "\n",
        "        return output_img\n",
        "\n",
        "\n",
        "# Initialize\n",
        "colorizer = ImageColorizationPipeline(model_path=model_path,\n",
        "                                      input_size=input_size,\n",
        "                                      model_size=model_size)\n",
        "\n",
        "\n",
        "# Create inference function for gradio app\n",
        "def colorize(img):\n",
        "  image_out = colorizer.process(img)\n",
        "  # Generate a unique filename using UUID\n",
        "  unique_imgfilename = str(uuid.uuid4()) + '.png'\n",
        "  cv2.imwrite(unique_imgfilename, image_out)\n",
        "  return (img, unique_imgfilename)\n",
        "\n",
        "\n",
        "# Gradio demo using the Image-Slider custom component\n",
        "with gr.Blocks() as demo:\n",
        "  with gr.Row():\n",
        "    with gr.Column():\n",
        "      bw_image = gr.Image(label='Black and White Input Image')\n",
        "      btn = gr.Button('Convert using DDColor')\n",
        "    with gr.Column():\n",
        "      col_image_slider = ImageSlider(position=0.5,\n",
        "                                     label='Colored Image with Slider-view')\n",
        "\n",
        "  btn.click(colorize, bw_image, col_image_slider)\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "e3TU4y5G7QQJ"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}